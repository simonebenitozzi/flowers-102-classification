{"cells":[{"cell_type":"markdown","metadata":{"id":"gnKCDHIh3YXl"},"source":["# Flowers Analysis\n","http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html\n","\n","102 Flower Category Database\n","----------------------------------------------\n","This set contains images of flowers belonging to 102 different categories. \n","The images were acquired by searching the web and taking pictures. There are a\n","minimum of 40 images for each category.\n","\n","The images are contained in the file 102flowers.tgz and the image labels in\n","imagelabels.mat.\n","\n","We provide 4 distance matrices. D_hsv, D_hog, D_siftint, D_siftbdy. These\n","are the chi^2 distance matrices used in the publication below.\n","\n","The database was used in:\n","\n","Nilsback, M-E. and Zisserman, A. Automated flower classification over a large number of classes.\n","Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing (2008) \n","http://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback08.{pdf,ps.gz}.\n","\n","Datasplit\n","------------------------------------------------\n","The datasplits used in this paper are specified in setid.mat.\n","\n","The results in the paper are produced on a 103 category database. The two\n","categories labeled Petunia have since been merged since they are the same.\n","There is a training file (trnid), a validation file (valid)\n","and a testfile (tstid). \n","\n","Segmentation Images\n","------------------------------------------------\n","We provide the segmentations for the images in the file 102segmentations.tgz\n","\n","More details can be found in:\n","\n","Nilsback, M-E. and Zisserman, A. Delving into the whorl of flower segmenation.\n","Proceedings of the British Machine Vision Conference (2007)\n","http:www.robots.ox.ac.uk/~vgg/publications/papers/nilsback07.(pdf,ps.gz).\n",".\n","\n","History\n","-----------------------------------------------\n","version 1.1 - Two petunia categories merged into one. "]},{"cell_type":"markdown","metadata":{"id":"VYsrgP6Mu-0N"},"source":["# Requirements"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s0T2NpbRvAcL"},"outputs":[],"source":["from google.colab import drive\n","\n","from os import listdir\n","from os.path import isfile, join\n","import os.path\n","from os import path\n","\n","import tarfile\n","import glob\n","\n","import tensorflow as tf\n","from sklearn.decomposition import PCA\n","\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","import scipy\n","from scipy import io\n","\n","import PIL\n","from PIL import Image\n","import cv2\n","import seaborn as sns\n","\n","from keras.utils import np_utils\n","\n","from tensorflow import keras\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","from tensorflow.keras.models import Model\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n","\n","from sklearn.utils import shuffle\n","from tensorflow.keras.layers import AveragePooling2D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","#from tensorflow.keras.applications import ResNet50"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Sc7koT5xkA7","outputId":"b62cf22d-8348-415b-b227-668d5bb3370b","executionInfo":{"status":"ok","timestamp":1673363063857,"user_tz":-60,"elapsed":71562,"user":{"displayName":"Kevin Moises Pretell Cadillo","userId":"17270428692932430189"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["drive.mount('/content/gdrive', force_remount=True)\n","PATH_PROJ = \"/content/gdrive/MyDrive/AML-proj/\" \n","if not path.exists(PATH_PROJ):\n","    PATH_PROJ = \"/content/gdrive/Shareddrives/AML-proj/\"  # TODO: check if it is correct!\n","\n","PATH_JPG = \"/content/jpg/\"\n","PATH_TAR = PATH_PROJ + \"102flowers.tgz\"\n","IMG_SIZE = 224\n","\n","NAMES = [\n","    \"pink primrose\", \"hard-leaved pocket orchid\", \"canterbury bells\",\n","    \"sweet pea\", \"english marigold\", \"tiger lily\", \"moon orchid\",\n","    \"bird of paradise\", \"monkshood\", \"globe thistle\", \"snapdragon\",\n","    \"colt's foot\", \"king protea\", \"spear thistle\", \"yellow iris\",\n","    \"globe-flower\", \"purple coneflower\", \"peruvian lily\", \"balloon flower\",\n","    \"giant white arum lily\", \"fire lily\", \"pincushion flower\", \"fritillary\",\n","    \"red ginger\", \"grape hyacinth\", \"corn poppy\", \"prince of wales feathers\",\n","    \"stemless gentian\", \"artichoke\", \"sweet william\", \"carnation\",\n","    \"garden phlox\", \"love in the mist\", \"mexican aster\", \"alpine sea holly\",\n","    \"ruby-lipped cattleya\", \"cape flower\", \"great masterwort\", \"siam tulip\",\n","    \"lenten rose\", \"barbeton daisy\", \"daffodil\", \"sword lily\", \"poinsettia\",\n","    \"bolero deep blue\", \"wallflower\", \"marigold\", \"buttercup\", \"oxeye daisy\",\n","    \"common dandelion\", \"petunia\", \"wild pansy\", \"primula\", \"sunflower\",\n","    \"pelargonium\", \"bishop of llandaff\", \"gaura\", \"geranium\", \"orange dahlia\",\n","    \"pink-yellow dahlia?\", \"cautleya spicata\", \"japanese anemone\",\n","    \"black-eyed susan\", \"silverbush\", \"californian poppy\", \"osteospermum\",\n","    \"spring crocus\", \"bearded iris\", \"windflower\", \"tree poppy\", \"gazania\",\n","    \"azalea\", \"water lily\", \"rose\", \"thorn apple\", \"morning glory\",\n","    \"passion flower\", \"lotus\", \"toad lily\", \"anthurium\", \"frangipani\",\n","    \"clematis\", \"hibiscus\", \"columbine\", \"desert-rose\", \"tree mallow\",\n","    \"magnolia\", \"cyclamen\", \"watercress\", \"canna lily\", \"hippeastrum\",\n","    \"bee balm\", \"ball moss\", \"foxglove\", \"bougainvillea\", \"camellia\", \"mallow\",\n","    \"mexican petunia\", \"bromelia\", \"blanket flower\", \"trumpet creeper\",\n","    \"blackberry lily\"\n","]\n","\n","NAMES_ID = dict(zip(NAMES, [x for x in range(len(NAMES))]))\n","ID_NAMES = dict(zip([x for x in range(len(NAMES))], NAMES))"]},{"cell_type":"markdown","metadata":{"id":"Xt7qG6MMr-ia"},"source":["# Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5cVUtKUsBP7"},"outputs":[],"source":["def execute_pca_on_imgs(img, show=False):\n","  # Splitting the image in R,G,B arrays.\n","  b, g, r = cv2.split(img) \n","  #it will split the original image into Blue, Green and Red arrays.\n","\n","  # it is mandatory to do feature scaling before applying PCA because PCA directions are highly sensitive to the relative ranges of features\n","  r_scaled = r / 255\n","  g_scaled = g / 255\n","  b_scaled = b / 255\n","\n","  #initialize PCA with at least 95% variance  \n","  pca_r = PCA(0.95)\n","  pca_r_trans = pca_r.fit_transform(r_scaled)\n","\n","  pca_g = PCA(0.95)\n","  pca_g_trans = pca_g.fit_transform(g_scaled)\n","\n","  pca_b = PCA(0.95)\n","  pca_b_trans = pca_b.fit_transform(b_scaled)\n","\n","  # inverse\n","  pca_r_org = pca_r.inverse_transform(pca_r_trans)\n","  pca_g_org = pca_g.inverse_transform(pca_g_trans)\n","  pca_b_org = pca_b.inverse_transform(pca_b_trans)\n","\n","  # compressiong\n","  img_compressed = cv2.merge((pca_b_org, pca_g_org, pca_r_org))\n","  #viewing the compressed image\n","  if show: \n","    plt.imshow(img_compressed)\n","    plt.show()\n","\n","  return img_compressed\n","    \n","\n","def execute_pca_on_imgs_set(df, path = PATH_JPG):\n","  for img_name in df[\"Id\"]:\n","    RGB_img = plt.imread(path + img_name)\n","    # im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    im_pca = execute_pca_on_imgs(RGB_img)\n","    cv2.imwrite(PATH_PROJ + \"jpg_pca/\" + img_name, 255*im_pca, [cv2.IMWRITE_JPEG_QUALITY])\n","    \n","\n","def processing_set(dataset, images, labels, size=224, return_pca=False):\n","  x, y = [], []\n","  for num_img in dataset:\n","    # print(f\"linking {num_img} to {images[num_img - 1]}\")\n","    path = PATH_JPG + images[num_img - 1]\n","    im=cv2.imread(path)\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    im=cv2.resize(im,(size,size))\n","    x.append(im)\n","    y.append(labels[num_img - 1])\n","  \n","  if return_pca:\n","    return execute_pca_on_imgs_set(x), np.asarray(y) \n","  else:\n","    return np.asarray(x), np.asarray(y)\n","\n","\n","def get_all_filenames(tar_fn):\n","    with tarfile.open(tar_fn) as f:\n","        return [m.name for m in f.getmembers() if m.isfile()]\n"]},{"cell_type":"markdown","metadata":{"id":"VSSAGozidmqr"},"source":["## Plot Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n0W-LVnDdE-l"},"outputs":[],"source":["def count_box_plot(unique_elem_dict, title, label):\n","\n","  list_value=np.array(list(unique_elem_dict.values()))\n","  fig, ax = plt.subplots()\n","\n","  # Save the chart so we can loop through the bars below.\n","  bars = ax.bar(range(len(unique_elem_dict)), list_value, align='center', tick_label=list(unique_elem_dict.keys()))\n","\n","  # Axis formatting.\n","  ax.spines['top'].set_visible(False)\n","  ax.spines['right'].set_visible(False)\n","  ax.spines['left'].set_visible(False)\n","  ax.spines['bottom'].set_color('#DDDDDD')\n","  ax.tick_params(bottom=False, left=False)\n","  ax.set_axisbelow(True)\n","  ax.yaxis.grid(True, color='#EEEEEE')\n","  ax.xaxis.grid(False)\n","\n","\n","  # Add labels and a title.\n","  ax.set_xlabel('Model type', labelpad=15, color='#333333')\n","  ax.set_ylabel(label, labelpad=15, color='#333333')\n","  ax.set_title(title, pad=15, color='#333333',\n","              weight='bold')\n","\n","  plt.show()\n","\n","\n","def plot_figure(df, path_figure = PATH_JPG):\n","  plt.figure(figsize=(16,12))\n","  random_image = df.sample(n=21)\n","  random_image_paths = random_image['Id'].values\n","  random_image_cat = random_image['Category'].values\n","\n","  for index, path in enumerate(random_image_paths):\n","      im = PIL.Image.open(path_figure+path)\n","      plt.subplot(3,7, index+1)\n","      plt.imshow(im)\n","      plt.title('Class: '+ NAMES[int(random_image_cat[index])])\n","      plt.axis('off')\n","  plt.show()\n","\n","\n","\n","def plot_figure_by_class(df, class_number, path_figure = PATH_JPG):\n","  plt.figure(figsize=(12,8))\n","\n","  random_image = df[df['Category']==class_number].sample(n=4)\n","  random_image_paths = random_image['Id'].values\n","  random_image_cat = random_image['Category'].values\n","\n","  for index, path in enumerate(random_image_paths):\n","      im = PIL.Image.open(path_figure+path)\n","      plt.subplot(1,4, index+1)\n","      plt.imshow(im)\n","      plt.title('Class: ' + NAMES[int(random_image_cat[index])])\n","      plt.axis('off')\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"W1SYKYVIvCrg"},"source":["# Import Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbZh4WoSvDau"},"outputs":[],"source":["# Import Dataset\n","%%capture\n","!tar -xvf '/content/gdrive/MyDrive/AML-proj/102flowers.tgz' -C '/content/'\n","images = [f for f in listdir(PATH_JPG) if isfile(join(PATH_JPG, f))]\n","images = sorted(images)\n","\n","df = pd.DataFrame()\n","df['Id'] = images\n","df['Category'] = scipy.io.loadmat(PATH_PROJ + 'imagelabels.mat')['labels'][0] - 1 \n","df['Category'] = df['Category'].astype(int)\n","#df.head(5)"]},{"cell_type":"code","source":["# Split Dataset con le rispettive label\n","split = scipy.io.loadmat(PATH_PROJ + 'setid.mat')\n","test_split = split[\"tstid\"][0] - 1 # start from zero\n","train_split = split[\"trnid\"][0] - 1\n","valid_split = split[\"valid\"][0] - 1\n","\n","train_set = df.iloc[train_split]\n","train_set['Category'].astype(int)\n","test_set = df.iloc[test_split]\n","test_set['Category'].astype(int)\n","val_set = df.iloc[valid_split]\n","val_set['Category'].astype(int)\n","\n","\n","train_set = train_set.reset_index(drop=True)\n","test_set = test_set.reset_index(drop=True)\n","val_set = val_set.reset_index(drop=True)\n","\n","print(\"Train set:\", train_set.shape, \"   Validation set:\", val_set.shape, \"   Test set:\", test_set.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OT82vpNjos3y","outputId":"f79ebfcf-8ce0-4c8a-cca3-dbe0d23d1e8a","executionInfo":{"status":"ok","timestamp":1673363292038,"user_tz":-60,"elapsed":434,"user":{"displayName":"Kevin Moises Pretell Cadillo","userId":"17270428692932430189"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train set: (1020, 2)    Validation set: (1020, 2)    Test set: (6149, 2)\n"]}]},{"cell_type":"code","source":["train_set"],"metadata":{"id":"8Q1dF3gBleYI","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1673363292039,"user_tz":-60,"elapsed":23,"user":{"displayName":"Kevin Moises Pretell Cadillo","userId":"17270428692932430189"}},"outputId":"a2b3862e-a4c5-4884-dcc4-5667b5b55be7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   Id  Category\n","0     image_06765.jpg         0\n","1     image_06755.jpg         0\n","2     image_06768.jpg         0\n","3     image_06736.jpg         0\n","4     image_06744.jpg         0\n","...               ...       ...\n","1015  image_08004.jpg       101\n","1016  image_08013.jpg       101\n","1017  image_08026.jpg       101\n","1018  image_08036.jpg       101\n","1019  image_08041.jpg       101\n","\n","[1020 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-e4e4a3ef-8a67-4b3b-83a9-5536cdd1f9fa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>image_06765.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>image_06755.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>image_06768.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>image_06736.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>image_06744.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1015</th>\n","      <td>image_08004.jpg</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>1016</th>\n","      <td>image_08013.jpg</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>1017</th>\n","      <td>image_08026.jpg</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>1018</th>\n","      <td>image_08036.jpg</td>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>1019</th>\n","      <td>image_08041.jpg</td>\n","      <td>101</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1020 rows Ã— 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4e4a3ef-8a67-4b3b-83a9-5536cdd1f9fa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e4e4a3ef-8a67-4b3b-83a9-5536cdd1f9fa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e4e4a3ef-8a67-4b3b-83a9-5536cdd1f9fa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Import effettivo delle immagini \n","x_train, y_train = [], []\n","size = 224\n","for index, row in train_set.iterrows():\n","    im = cv2.imread('jpg/' + row['Id'])\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    im = cv2.resize(im,(size,size))\n","    x_train.append(im)\n","    y_train.append(row['Category'])\n","\n","x_train=np.asarray(x_train)\n","y_train=np.asarray(y_train)\n","\n","\n","x_val, y_val = [], []\n","for index, row in val_set.iterrows():\n","    im = cv2.imread('jpg/' + row['Id'])\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    im = cv2.resize(im,(size,size))\n","    x_val.append(im)\n","    y_val.append(row['Category'])\n","\n","x_val=np.asarray(x_val)\n","y_val=np.asarray(y_val)\n","\n","\n","x_test, y_test = [], []\n","for index, row in test_set.iterrows():\n","    im = cv2.imread('jpg/' + row['Id'])\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    im = cv2.resize(im,(size,size))\n","    x_test.append(im)\n","    y_test.append(row['Category'])\n","\n","x_test=np.asarray(x_test)\n","y_test=np.asarray(y_test)"],"metadata":{"id":"NWpD2qdgmrl5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ResNet 50 - Feature Extraction\n","\n"],"metadata":{"id":"lbffH8dxePOS"}},{"cell_type":"code","source":["# Creazione modello\n","base_model = ResNet50(weights='imagenet')\n","model = Model(inputs = base_model.input , outputs=base_model.get_layer('avg_pool').output)\n","base_model.summary()"],"metadata":{"id":"XjvwWgtEeoO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Estraggo Features Train + Reshape Features\n","feat_train = model.predict(x_train)\n","feat_train = np.array( [feat_train[i].flatten() for i in range(x_train.shape[0])])"],"metadata":{"id":"27QYWrlPiBUh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4aa0bd5-a0f6-4375-943c-3d026b4d39ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 12s 101ms/step\n"]}]},{"cell_type":"code","source":["# Estraggo Feature Test + Reshape Features\n","feat_test = model.predict(x_val)\n","feat_test = np.array( [feat_test[i].flatten() for i in range(x_val.shape[0])])"],"metadata":{"id":"8Z20dakBiCxL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1b976cad-ff7f-44a0-f45e-4450cc075151"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 3s 81ms/step\n"]}]},{"cell_type":"code","source":["# Classificatore\n","knn = KNeighborsClassifier(n_neighbors = 5)\n","knn.fit(feat_train, y_train)\n","\n","# Predizioni\n","predizioni = knn.predict(feat_test)\n","\n","# Matrice di confusione\n","result = confusion_matrix(y_val, predizioni)\n","#disp = ConfusionMatrixDisplay(confusion_matrix=result)\n","#disp.plot()\n","\n","\n","#Accuracy\n","accuracy_score(y_val, predizioni)"],"metadata":{"id":"yK5jZEstiG_e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d9e9e9c-6ffe-4536-e70a-8fa6827392db"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6098039215686275"]},"metadata":{},"execution_count":44}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["VYsrgP6Mu-0N","Xt7qG6MMr-ia","W1SYKYVIvCrg"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}